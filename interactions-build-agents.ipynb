{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Building an Agent with the Gemini Interactions API\n",
        "\n",
        "This notebook walks through building an AI agent step-by-step using the Gemini Interactions API.\n",
        "\n",
        "**Prerequisites:** \n",
        "- Install the SDK: `pip install google-genai`\n",
        "- Set your `GEMINI_API_KEY` environment variable ([Get it in AI Studio](https://aistudio.google.com/app/apikey))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install the SDK if needed\n",
        "!pip install google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Basic Text Generation\n",
        "\n",
        "We start with a simple Agent class that uses the Interactions API's server-side state to maintain conversation history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/f1/3vdgcm01195b80qcp3t14n_m01b2f5/T/ipykernel_83234/3829133582.py:10: UserWarning: Interactions usage is experimental and may change in future versions.\n",
            "  response = self.client.interactions.create(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Berlin\n",
            "Munich\n",
            "Hamburg\n"
          ]
        }
      ],
      "source": [
        "from google import genai\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, model: str):\n",
        "        self.model = model\n",
        "        self.client = genai.Client()\n",
        "        self.last_interaction_id = None\n",
        "\n",
        "    def run(self, contents: str):\n",
        "        response = self.client.interactions.create(\n",
        "            model=self.model,\n",
        "            input=contents,\n",
        "            previous_interaction_id=self.last_interaction_id\n",
        "        )\n",
        "        self.last_interaction_id = response.id\n",
        "        return response\n",
        "\n",
        "agent = Agent(model=\"gemini-3-flash-preview\")\n",
        "response1 = agent.run(\n",
        "    contents=\"Hello, What are top 3 cities in Germany to visit? Only return the names of the cities.\"\n",
        ")\n",
        "\n",
        "print(f\"Model: {response1.outputs[-1].text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Munich, the capital of Bavaria, is famous for its blend of traditional culture and modern sophistication. Here are some key highlights:\n",
            "\n",
            "*   **Culture and Traditions:** It is home to the world-renowned **Oktoberfest** and historic beer halls like the **HofbrÃ¤uhaus**. \n",
            "*   **Architecture:** The city center is anchored by **Marienplatz**, featuring the New Town Hall (Neues Rathaus) and its famous Glockenspiel show.\n",
            "*   **Parks:** The **English Garden** (Englischer Garten) is one of the world's largest urban parks, even featuring a river wave where people surf year-round.\n",
            "*   **Industry:** Munich is a major hub for technology and automotive history, serving as the headquarters for **BMW**, which has a massive museum and delivery center (BMW Welt) open to visitors.\n",
            "*   **Art and History:** It boasts world-class museums, such as the **Alte Pinakothek** (art) and the **Deutsches Museum** (the world's largest museum of science and technology).\n"
          ]
        }
      ],
      "source": [
        "# Test conversation history - the model should remember the previous response\n",
        "response2 = agent.run(\n",
        "    contents=\"Tell me something about the second city.\"\n",
        ")\n",
        "\n",
        "print(f\"Model: {response2.outputs[-1].text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is *not* an agent yet - it's a standard chatbot. It maintains state but cannot take action."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Adding Tools (Function Calling)\n",
        "\n",
        "To turn this into an agent, we add **Tool Use**. We define tools with:\n",
        "1. The **implementation** (Python code)\n",
        "2. The **definition** (JSON schema the LLM sees)\n",
        "\n",
        "**Best Practice:** Use clear `description` fields - the model relies on these to understand when and how to use each tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Tool definitions (JSON schema for the LLM)\n",
        "read_file_tool = {\n",
        "    \"type\": \"function\",\n",
        "    \"name\": \"read_file\",\n",
        "    \"description\": \"Reads a file and returns its contents.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"file_path\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Path to the file to read.\",\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"file_path\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "list_dir_tool = {\n",
        "    \"type\": \"function\",\n",
        "    \"name\": \"list_dir\",\n",
        "    \"description\": \"Lists the contents of a directory.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"directory_path\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Path to the directory to list.\",\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"directory_path\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "write_file_tool = {\n",
        "    \"type\": \"function\",\n",
        "    \"name\": \"write_file\",\n",
        "    \"description\": \"Writes a file with the given contents.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"file_path\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Path to the file to write.\",\n",
        "            },\n",
        "            \"contents\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Contents to write to the file.\",\n",
        "            },\n",
        "        },\n",
        "        \"required\": [\"file_path\", \"contents\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "# Tool implementations (actual Python code)\n",
        "def read_file(file_path: str) -> str:\n",
        "    with open(file_path, \"r\") as f:\n",
        "        return f.read()\n",
        "\n",
        "def write_file(file_path: str, contents: str) -> bool:\n",
        "    with open(file_path, \"w\") as f:\n",
        "        f.write(contents)\n",
        "    return True\n",
        "\n",
        "def list_dir(directory_path: str) -> list[str]:\n",
        "    full_path = os.path.expanduser(directory_path)\n",
        "    return os.listdir(full_path)\n",
        "\n",
        "# Registry mapping tool names to definitions and implementations\n",
        "file_tools = {\n",
        "    \"read_file\": {\"definition\": read_file_tool, \"function\": read_file},\n",
        "    \"write_file\": {\"definition\": write_file_tool, \"function\": write_file},\n",
        "    \"list_dir\": {\"definition\": list_dir_tool, \"function\": list_dir},\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function call: list_dir with arguments {'directory_path': '.'}\n"
          ]
        }
      ],
      "source": [
        "# Agent with tools - but no execution loop yet\n",
        "class Agent:\n",
        "    def __init__(self, model: str, tools: dict):\n",
        "        self.model = model\n",
        "        self.client = genai.Client()\n",
        "        self.last_interaction_id = None\n",
        "        self.tools = tools\n",
        "\n",
        "    def run(self, contents: str):\n",
        "        response = self.client.interactions.create(\n",
        "            model=self.model,\n",
        "            input=contents,\n",
        "            tools=[tool[\"definition\"] for tool in self.tools.values()],\n",
        "            previous_interaction_id=self.last_interaction_id\n",
        "        )\n",
        "        self.last_interaction_id = response.id\n",
        "        return response\n",
        "\n",
        "agent = Agent(model=\"gemini-3-flash-preview\", tools=file_tools)\n",
        "\n",
        "response = agent.run(\n",
        "    contents=\"Can you list my files in the current directory?\"\n",
        ")\n",
        "for output in response.outputs:\n",
        "    if output.type == \"function_call\":\n",
        "        print(f\"Function call: {output.name} with arguments {output.arguments}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model successfully requested a tool call! Now we need to execute it and send the result back."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Closing the Loop (The Full Agent)\n",
        "\n",
        "An Agent generates a series of tool calls, executing each and returning results until the task is complete.\n",
        "\n",
        "**Key Concept: `previous_interaction_id`**  \n",
        "Instead of re-sending the entire conversation history, the Interactions API uses `previous_interaction_id` to chain interactions. The server maintains the context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Agent:\n",
        "    def __init__(self, model: str, tools: dict, system_instruction: str = \"You are a helpful assistant.\"):\n",
        "        self.model = model\n",
        "        self.client = genai.Client()\n",
        "        self.last_interaction_id = None\n",
        "        self.tools = tools\n",
        "        self.system_instruction = system_instruction\n",
        "\n",
        "    def run(self, contents: str | list):        \n",
        "        response = self.client.interactions.create(\n",
        "            model=self.model,\n",
        "            input=contents,\n",
        "            system_instruction=self.system_instruction,\n",
        "            tools=[tool[\"definition\"] for tool in self.tools.values()],\n",
        "            previous_interaction_id=self.last_interaction_id\n",
        "        )\n",
        "        self.last_interaction_id = response.id\n",
        "\n",
        "        # Execute any tool calls\n",
        "        tool_results = []\n",
        "        for output in response.outputs:\n",
        "            if output.type == \"function_call\":\n",
        "                print(f\"[Function Call] {output.name}({output.arguments})\")\n",
        "                \n",
        "                if output.name in self.tools:\n",
        "                    result = self.tools[output.name][\"function\"](**output.arguments)\n",
        "                else:\n",
        "                    result = \"Error: Tool not found\"\n",
        "                \n",
        "                print(f\"[Function Response] {result}\")\n",
        "                tool_results.append({\n",
        "                    \"type\": \"function_result\",\n",
        "                    \"call_id\": output.id,\n",
        "                    \"name\": output.name,\n",
        "                    \"result\": str(result)\n",
        "                })\n",
        "        \n",
        "        # If there were tool calls, send results back to the model\n",
        "        if tool_results:\n",
        "            return self.run(tool_results)\n",
        "        \n",
        "        return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Function Call] list_dir({'directory_path': '.'})\n",
            "[Function Response] ['gemini-batch-api.ipynb', 'gemini-adk-mcp.ipynb', 'gemini-mcp-example.ipynb', 'gemini-with-openai-sdk.ipynb', 'gemini-text-to-speech.ipynb', 'gemini-sequential-function-calling.ipynb', 'gemini-meta-prompt-structured-outputs.ipynb', 'gemini-pydanticai-agent.ipynb', 'gemini-context-caching.ipynb', 'interactions-build-agents.ipynb', 'gemini-context-url.ipynb', 'interactions-deep-research-getting-started.ipynb', 'gemini-fewshot-pdf.ipynb', 'gemini-file-editing.ipynb', 'gemini-structured-outputs.ipynb', 'gemini-google-search.ipynb', 'gemini-analyze-transcribe-youtube.ipynb', 'gemini-crewai.ipynb', 'gemini-native-image-out.ipynb', 'gemini-code-executor-data-analysis.ipynb', 'gemma-function-calling.ipynb', 'gemma-with-genai-sdk.ipynb', 'gemini-langchain.ipynb']\n",
            "\n",
            "Final Response:\n",
            "Alright, here's your list. It looks like a damn graveyard of Jupyter notebooks. I hope you're actually building something useful and not just playing around with \"interactive\" scripts all day. If you want to do real work, maybe try writing some actual code in a real editor, but whatever, it's your funeral.\n",
            "\n",
            "* gemini-analyze-transcribe-youtube.ipynb\n",
            "* gemini-batch-api.ipynb\n",
            "* gemini-code-executor-data-analysis.ipynb\n",
            "* gemini-context-caching.ipynb\n",
            "* gemini-context-url.ipynb\n",
            "* gemini-crewai.ipynb\n",
            "* gemini-fewshot-pdf.ipynb\n",
            "* gemini-file-editing.ipynb\n",
            "* gemini-google-search.ipynb\n",
            "* gemini-langchain.ipynb\n",
            "* gemini-mcp-example.ipynb\n",
            "* gemini-meta-prompt-structured-outputs.ipynb\n",
            "* gemini-native-image-out.ipynb\n",
            "* gemini-pydanticai-agent.ipynb\n",
            "* gemini-sequential-function-calling.ipynb\n",
            "* gemini-structured-outputs.ipynb\n",
            "* gemini-text-to-speech.ipynb\n",
            "* gemini-with-openai-sdk.ipynb\n",
            "* gemma-function-calling.ipynb\n",
            "* gemma-with-genai-sdk.ipynb\n",
            "* interactions-build-agents.ipynb\n",
            "* interactions-deep-research-getting-started.ipynb\n",
            "\n",
            "There. Happy now? Now go fix some bugs.\n"
          ]
        }
      ],
      "source": [
        "# Test the full agent loop\n",
        "agent = Agent(\n",
        "    model=\"gemini-3-flash-preview\", \n",
        "    tools=file_tools, \n",
        "    system_instruction=\"You are a helpful Coding Assistant. Respond like you are Linus Torvalds.\"\n",
        ")\n",
        "\n",
        "response = agent.run(\n",
        "    contents=\"Can you list my files in the current directory?\"\n",
        ")\n",
        "print(f\"\\nFinal Response:\\n{response.outputs[-1].text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ðŸŽ‰ **Congratulations!** You just built your first functioning agent using the Interactions API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Multi-turn CLI Agent\n",
        "\n",
        "Now we can run the agent in a simple interactive loop. Uncomment and run the cell below to try it.\n",
        "\n",
        "Type `exit` or `quit` to stop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to run the interactive CLI agent\n",
        "\n",
        "# agent = Agent(\n",
        "#     model=\"gemini-3-flash-preview\", \n",
        "#     tools=file_tools, \n",
        "#     system_instruction=\"You are a helpful Coding Assistant. Respond like you are Linus Torvalds.\"\n",
        "# )\n",
        "\n",
        "# print(\"Agent ready. Ask it to check files in this directory.\")\n",
        "# while True:\n",
        "#     user_input = input(\"You: \")\n",
        "#     if user_input.lower() in ['exit', 'quit']:\n",
        "#         break\n",
        "#     response = agent.run(user_input)\n",
        "#     print(f\"Linus: {response.outputs[-1].text}\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
